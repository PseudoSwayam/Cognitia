# ğŸ§  Cognitia â€“ Agentic AI Research Mentor with Debate Reasoning

> Your personal AI-powered academic research companion â€” built to simulate expert mentorship via semantic understanding, debate reasoning, and adaptive conversation.

---

## ğŸ“š Overview

**Cognitia** is a full-stack, AI-driven research assistant designed to **semantically fetch** and **debate academic content** from sources like **ArXiv papers** and **YouTube lectures**. It enables researchers and students to gain **expert-level insights** through an agentic, reasoning-based interaction layer.

> Powered by [FastAPI](https://fastapi.tiangolo.com/), [React + TypeScript](https://react.dev/), [LangChain](https://www.langchain.com/), and [Mistral via Ollama](https://ollama.com/).

---

## ğŸ§  Features

- ğŸ“– **Academic Content Fetching** from ArXiv & YouTube
- ğŸ—£ï¸ **Debate Simulation** for deeper understanding
- ğŸ§© **Semantic Indexing & Reasoning** using vector databases
- ğŸ§µ **Tone-Adaptive Conversations** using LLMs (Mistral)
- ğŸ“¦ **Offline-Ready Chat** with persistent memory
- âš™ï¸ **Modular FastAPI Backend** + Clean React Frontend

---

## ğŸ› ï¸ Tech Stack

### ğŸ”¹ Backend
- `FastAPI`, `LangChain`, `Ollama (Mistral)`
- `ChromaDB`, `SQLite`
- `Python`, `ArXiv API`, `YouTube API`

### ğŸ”¹ Frontend
- `React`, `TypeScript`, `TailwindCSS`
- `Vite`, `Component-Based UI`

---

## ğŸ“ Project Structure

```
Cognitia/
â”‚
â”œâ”€â”€ Cognitia Backend/
â”‚   â”œâ”€â”€ data/                  # Raw, processed, vector DBs
â”‚   â”œâ”€â”€ debate/                # Debate engine (LLM-based)
â”‚   â”œâ”€â”€ fetchers/              # Arxiv and YouTube content fetchers
â”‚   â”œâ”€â”€ memory/                # Local memory handling
â”‚   â”œâ”€â”€ ollama_utils/          # Ollama + Mistral helpers
â”‚   â”œâ”€â”€ semantic_engine/       # Vector DB + similarity engine
â”‚   â”œâ”€â”€ utils/                 # Parsing utilities
â”‚   â”œâ”€â”€ app.py                 # FastAPI app entrypoint
â”‚   â””â”€â”€ main.py                # Debug or launch script
â”‚
â”œâ”€â”€ Cognitia FrontEnd/
â”‚   â”œâ”€â”€ src/components/        # Modular UI: Chat, Sidebar, etc.
â”‚   â”œâ”€â”€ services/              # API calling layer
â”‚   â”œâ”€â”€ types/                 # TypeScript interfaces
â”‚   â”œâ”€â”€ App.tsx / main.tsx     # Frontend root
â”‚   â””â”€â”€ index.html / Tailwind / Vite config
â”‚
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore
```
---

## âš¡ Getting Started

ğŸ”§ Backend (Python + FastAPI)
```bash
cd 'Cognitia Backend'
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python3 app.py
```

ğŸ’» Frontend (React + Vite)

```bash
cd 'Cognitia FrontEnd'
npm install
npm run dev
```

â¸»

ğŸ§ª Demo Use Cases
	â€¢	Ask: â€œSummarize and debate the claims of this ArXiv paperâ€
	â€¢	Ask: â€œWhat are the counterarguments in this YouTube lecture?â€
	â€¢	Ask: â€œGive a mentorâ€™s response vs a criticâ€™s viewâ€

â¸»

ğŸ“Œ Roadmap
	â€¢	Add local PDF upload + analysis
	â€¢	Export debate logs as reports
	â€¢	Improve real-time LLM streaming
	â€¢	Integrate citation-aware memory

â¸»

ğŸªª License

This project is licensed under the MIT License

â¸»

ğŸ¤ Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.

â¸»

ğŸ“¬ Contact

Built with â¤ï¸ by Swayam Sahoo
For collaboration, reach out via LinkedIn or GitHub.

---

## âœ… What You Should Do Next

1. Create a file:
```bash
touch README.md

	2.	Paste the entire markdown above.
	3.	Commit and push:

git add README.md
git commit -m "Added professional README for Cognitia"
git push
```

â¸»
